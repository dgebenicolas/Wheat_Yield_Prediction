{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from geemap import geojson_to_ee, ee_to_geojson\n",
    "from ipyleaflet import GeoJSON\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize(project = 'ee-project-id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Wheat Field Coordinate Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2 = r\"/home/user/Wheat_Field_Polygons/FIELDS_For_Wheat_2020.geojson\"\n",
    "file_path3 = r\"/home/user/Wheat_Field_Polygons/FIELDS_For_Wheat_2021.geojson\"\n",
    "file_path4 = r\"/home/user/Wheat_Field_Polygons/FIELDS_For_Wheat_2022.geojson\"\n",
    "file_path5 = r\"/home/user/Wheat_Field_Polygons/FIELDS_For_Wheat_2023.geojson\"\n",
    "file_path_6 = r\"/home/user/Wheat_Field_Polygons/FIELDS_For_Wheat_2024.geojson\"\n",
    "file_paths = [file_path2,file_path3,file_path4,file_path5, file_path_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        with open(file_path, encoding='utf-8', errors='replace') as f:\n",
    "            json_data = json.load(f)\n",
    "            json_list.append(json_data)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing file {file_path}: {e}')\n",
    "\n",
    "print(len(json_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_2020 = geojson_to_ee(json_list[0])\n",
    "fields_2021 = geojson_to_ee(json_list[1])\n",
    "fields_2022 = geojson_to_ee(json_list[2])\n",
    "fields_2023 = geojson_to_ee(json_list[3])\n",
    "fields_2024 = geojson_to_ee(json_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reduce_region_function(geometry, reducer=ee.Reducer.mean(), scale=10, crs='EPSG:4326', bestEffort=True, maxPixels=1e13, tileScale=4):\n",
    "    \"\"\"Creates a function that reduces an Earth Engine image to regional statistics based on given parameters\n",
    "    \n",
    "    Returns a function that takes an image as input and outputs an Earth Engine Feature containing the computed statistics\"\"\"\n",
    "    def reduce_region_function(img):\n",
    "        stat = img.reduceRegion(\n",
    "            reducer=reducer,\n",
    "            geometry=geometry, \n",
    "            scale=scale,\n",
    "            crs=crs,\n",
    "            bestEffort=bestEffort,\n",
    "            maxPixels=maxPixels,\n",
    "            tileScale=tileScale)\n",
    "        return ee.Feature(geometry, stat)\n",
    "    return reduce_region_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading NDVI Data for June and July 2020-2024 using Sentinel - 2 with GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_mask(image):\n",
    "    \"\"\"Applies cloud masking to Sentinel-2 images using the Scene Classification Layer (SCL)\"\"\"\n",
    "    scl = image.select('SCL')\n",
    "    mask = scl.eq(3).Or(scl.gte(7).And(scl.lte(10)))\n",
    "    return image.updateMask(mask.eq(0))\n",
    "\n",
    "def calculate_s2_ndvi(image):\n",
    "    \"\"\"Calculates NDVI from Sentinel-2 imagery using bands B8 (NIR) and B4 (Red)\"\"\"\n",
    "    return image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "\n",
    "def process_field(feature):\n",
    "    \"\"\"Processes Sentinel-2 imagery for a given field feature to extract NDVI statistics\n",
    "    \n",
    "    Filters image collection by date and cloud cover, applies cloud masking, \n",
    "    calculates NDVI, and returns median NDVI value for the field geometry\"\"\"\n",
    "    field_id = feature.get('Field_ID')\n",
    "    geometry = feature.geometry()\n",
    "    s2_50cc = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "               .filterDate(start_date, end_date)\n",
    "               .filterBounds(geometry)\n",
    "               .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', 50))\n",
    "               .map(cloud_mask)\n",
    "               .map(calculate_s2_ndvi)\n",
    "               .median()\n",
    "               .select('NDVI')\n",
    "    )\n",
    "\n",
    "    def map_func(image):\n",
    "        stats = image.reduceRegion(\n",
    "            reducer=ee.Reducer.median().setOutputs(['NDVI']),\n",
    "            geometry=geometry,\n",
    "            scale=10,\n",
    "            maxPixels=1e13,\n",
    "            bestEffort=True\n",
    "        )\n",
    "        ndvi = ee.List([stats.get('NDVI'), -9999]).reduce(ee.Reducer.firstNonNull())\n",
    "        return ee.Feature(geometry, {\n",
    "            'Field_ID': field_id,\n",
    "            'NDVI': ndvi,\n",
    "            'date': start_date\n",
    "        })\n",
    "    \n",
    "    return map_func(s2_50cc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch processes Sentinel-2 satellite imagery to calculate and export NDVI data for agricultural fields across 2020-2024.\n",
    "date_ranges = [\n",
    "    ('06-01', '07-01'),\n",
    "    ('07-01', '08-01')\n",
    "]\n",
    "\n",
    "fields = {\n",
    "    2020: fields_2020,\n",
    "    2021: fields_2021,\n",
    "    2022: fields_2022,\n",
    "    2023: fields_2023,\n",
    "    2024: fields_2024\n",
    "}\n",
    "\n",
    "for year, field in fields.items():\n",
    "    for start_month, end_month in date_ranges:\n",
    "        start_date = ee.Date(f'{year}-{start_month}')\n",
    "        end_date = ee.Date(f'{year}-{end_month}')\n",
    "        \n",
    "        all_fields = field.map(process_field)\n",
    "        all_fields_filtered = all_fields.filter(ee.Filter.neq('NDVI', -9999))\n",
    "        \n",
    "        export_task = ee.batch.Export.table.toDrive(\n",
    "            collection=all_fields_filtered,\n",
    "            description=f'{start_month}_NEW_NDVI_{year}_export',\n",
    "            fileFormat='CSV',\n",
    "            folder='Earth_Engine_Exports'  # This folder will be created in your Google Drive\n",
    "        )\n",
    "\n",
    "        export_task.start()\n",
    "            \n",
    "        # Wait for the task to complete\n",
    "        while export_task.active():\n",
    "            print(f'Waiting for task {export_task.id} to complete...')\n",
    "            time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "            \n",
    "    print(f'Task for {year} completed.')\n",
    "\n",
    "print(\"All tasks completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Maximum NDVI during the growing season from Sentinel - 2 Images using GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_field_max(feature):\n",
    "    \"\"\"Processes Sentinel-2 imagery to extract NDVI statistics for each image in collection\n",
    "    \n",
    "    Filters imagery by 30% cloud cover threshold, calculates NDVI, and returns collection \n",
    "    of features containing field-level NDVI values with corresponding image IDs\"\"\"\n",
    "    field_id = feature.get('Field_ID')\n",
    "    geometry = feature.geometry()\n",
    "    s2_50cc = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "               .filterDate(start_date, end_date)\n",
    "               .filterBounds(geometry)\n",
    "               .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
    "               .map(cloud_mask)\n",
    "               .map(calculate_s2_ndvi)\n",
    "               .select('NDVI'))\n",
    "\n",
    "    def map_func(image):\n",
    "        stats = image.reduceRegion(\n",
    "            reducer=ee.Reducer.median().setOutputs(['NDVI']),\n",
    "            geometry=geometry,\n",
    "            scale=10,\n",
    "            maxPixels=1e13,\n",
    "            bestEffort=True\n",
    "        )\n",
    "        ndvi = ee.List([stats.get('NDVI'), -9999]).reduce(ee.Reducer.firstNonNull())\n",
    "        return ee.Feature(geometry, {\n",
    "            'Field_ID': field_id,\n",
    "            'NDVI': ndvi,\n",
    "            'imageID': image.id()\n",
    "        })\n",
    "    \n",
    "    return s2_50cc.map(map_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\n",
    "    2020: fields_2020,\n",
    "    2021: fields_2021,\n",
    "    2022: fields_2022,\n",
    "    2023: fields_2023,\n",
    "    2024: fields_2024\n",
    "}\n",
    "\n",
    "for year, fields in fields.items():\n",
    "    start_date = ee.Date(f'{year}-06-01')\n",
    "    end_date = ee.Date(f'{year}-08-01')\n",
    "        \n",
    "    all_fields = fields.map(process_field_max).flatten()\n",
    "    all_fields_with_date = all_fields.map(lambda f: f.set('date', ee.String(f.get('imageID')).slice(0, 8)))\n",
    "    all_fields_filtered = all_fields_with_date.filter(ee.Filter.neq('NDVI', -9999))\n",
    "        \n",
    "    export_task = ee.batch.Export.table.toDrive(\n",
    "        collection=all_fields_filtered,\n",
    "        description=f'MAX_NDVI_{year}_export',\n",
    "        fileFormat='CSV',\n",
    "        folder='Earth_Engine_Exports'  # This folder will be created in your Google Drive\n",
    "    )\n",
    "\n",
    "    export_task.start()\n",
    "        \n",
    "    # Wait for the task to complete\n",
    "    while export_task.active():\n",
    "        print(f'Waiting for task {export_task.id} to complete...')\n",
    "        time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "        \n",
    "    print(f'Task for {year} completed.')\n",
    "\n",
    "print(\"All tasks completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Climate Data from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reduce_region_function(geometry,\n",
    "                                  reducer=ee.Reducer.mean(),\n",
    "                                  scale=1000,\n",
    "                                  crs='EPSG:4326',\n",
    "                                  bestEffort=True,\n",
    "                                  maxPixels=1e13,\n",
    "                                  tileScale=4):\n",
    "    \"\"\"Creates a function that reduces an Earth Engine image to regional statistics based on given parameters\n",
    "Returns a function that takes an image as input and outputs an Earth Engine Feature containing the computed statistics with correct date\"\"\"\n",
    "    def reduce_region_function(img):\n",
    "        stat = img.reduceRegion(\n",
    "            reducer=reducer,\n",
    "            geometry=geometry,\n",
    "            scale=scale,\n",
    "            crs=crs,\n",
    "            bestEffort=bestEffort,\n",
    "            maxPixels=maxPixels,\n",
    "            tileScale=tileScale)\n",
    "        return ee.Feature(geometry, stat).set({'date': img.date().format('YYYY-MM-dd')})\n",
    "    return reduce_region_function\n",
    "\n",
    "def process_daily_climate(feature):\n",
    "    \"\"\"Extracts ERA5-Land monthly climate variables (temperature, precipitation, radiation, wind) for agricultural fields\n",
    "    \n",
    "    Creates a feature collection containing field-level climate statistics using 1km resolution data from ERA5-Land\"\"\"\n",
    "    geometry = feature.geometry()\n",
    "    field_id = feature.get('Field_ID')\n",
    "    \n",
    "    climate_images = (ee.ImageCollection(\"ECMWF/ERA5_LAND/MONTHLY_AGGR\")\n",
    "                  .select(\"temperature_2m\",\"total_precipitation_sum\", \"dewpoint_temperature_2m\", \"surface_solar_radiation_downwards_sum\",\"v_component_of_wind_10m\",\"temperature_2m_min\",\"temperature_2m_max\" )\n",
    "                  .filter(ee.Filter.date(start_date,end_date))\n",
    "                  )\n",
    "    \n",
    "    reduce_climate = create_reduce_region_function(\n",
    "        geometry=geometry, reducer=ee.Reducer.mean(), scale=1000, crs='EPSG:4326')\n",
    "    \n",
    "    climate_stat_fc = ee.FeatureCollection(climate_images.map(reduce_climate))\n",
    "    \n",
    "    return climate_stat_fc.map(lambda f: f.set('Field_ID', field_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\n",
    "    2020: fields_2020,\n",
    "    2021: fields_2021,\n",
    "    2022: fields_2022,\n",
    "    2023: fields_2023,\n",
    "    2024: fields_2024\n",
    "}\n",
    "years = list(range(2004, 2025))\n",
    "#all_climate_data = ee.FeatureCollection([])\n",
    "for year, fields in fields.items():\n",
    "    start_date = ee.Date(f'{year}-05-01')\n",
    "    end_date = ee.Date(f'{year}-09-01')\n",
    "        \n",
    "    year_climate_data = fields.map(process_daily_climate).flatten()\n",
    "    \n",
    "    export_task = ee.batch.Export.table.toDrive(\n",
    "        collection= year_climate_data,\n",
    "        description=f'Wheat_Climate_Data_{year}_export',\n",
    "        fileFormat='CSV',\n",
    "        folder='Earth_Engine_Exports'  # This folder will be created in your Google Drive\n",
    "    )\n",
    "\n",
    "    export_task.start()\n",
    "        \n",
    "    # Wait for the task to complete\n",
    "    while export_task.active():\n",
    "        print(f'Waiting for task {export_task.id} to complete...')\n",
    "        time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "        \n",
    "    print(f'Task for {year} completed.')\n",
    "\n",
    "print(\"All tasks completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Soil Info Data using the SOILGRIDS Dataset on GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_field(feature):\n",
    "    geometry = feature.geometry()\n",
    "    field_id = feature.get('Field_ID')\n",
    "    \n",
    "    soil_images = get_soil_images()\n",
    "    \n",
    "    soil_data = {}\n",
    "    for key, img in soil_images.items():\n",
    "        soil_stats = img.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=geometry,\n",
    "            scale=250, \n",
    "            maxPixels=1e13,\n",
    "            bestEffort=True\n",
    "        )\n",
    "        soil_data[key] = soil_stats.get(img.bandNames().get(0))\n",
    "    \n",
    "    soil_data['Field_ID'] = field_id\n",
    "    \n",
    "    return ee.Feature(None, soil_data)\n",
    "\n",
    "def process_field(feature):\n",
    "    \"\"\"Extracts mean soil properties from SoilGrids at 250m resolution for each field\n",
    "    \n",
    "    Takes a field feature and returns a new feature containing averaged soil characteristics \n",
    "    (bulk density, organic carbon, pH, CEC, texture) with the field ID\"\"\"\n",
    "    geometry = feature.geometry()\n",
    "    field_id = feature.get('Field_ID')\n",
    "    \n",
    "    soil_images = get_soil_images()\n",
    "    \n",
    "    soil_data = {}\n",
    "    for key, img in soil_images.items():\n",
    "        soil_stats = img.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=geometry,\n",
    "            scale=250, \n",
    "            maxPixels=1e13,\n",
    "            bestEffort=True\n",
    "        )\n",
    "        soil_data[key] = soil_stats.get(img.bandNames().get(0))\n",
    "    \n",
    "    soil_data['Field_ID'] = field_id\n",
    "    \n",
    "    return ee.Feature(None, soil_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\n",
    "    2020: fields_2020,\n",
    "    2021: fields_2021,\n",
    "    2022: fields_2022,\n",
    "    2023: fields_2023,\n",
    "    2024: fields_2024\n",
    "}\n",
    "#all_climate_data = ee.FeatureCollection([])\n",
    "for year, fields in fields.items():\n",
    "\n",
    "    soil_data = fields.map(process_field)\n",
    "    \n",
    "    export_task = ee.batch.Export.table.toDrive(\n",
    "        collection= soil_data,\n",
    "        description=f'Soil_Data_Flakes{year}_export',\n",
    "        fileFormat='CSV',\n",
    "        folder='Earth_Engine_Exports'  # This folder will be created in your Google Drive\n",
    "    )\n",
    "\n",
    "    export_task.start()\n",
    "        \n",
    "    # Wait for the task to complete\n",
    "    while export_task.active():\n",
    "        print(f'Waiting for task {export_task.id} to complete...')\n",
    "        time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "        \n",
    "    print(f'Task for {year} completed.')\n",
    "\n",
    "print(\"All tasks completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
